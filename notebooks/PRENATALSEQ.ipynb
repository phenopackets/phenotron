{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9d0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopackets as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from pyphetools.creation import *\n",
    "import logging\n",
    "\n",
    "def done():\n",
    "    logging.info(\"Done..\")\n",
    "    \n",
    "from hpotk import Ontology\n",
    "from hpotk.ontology.load.obographs import load_ontology\n",
    "\n",
    "logging.info(\"Loading graph data..\")\n",
    "o: Ontology = load_ontology('http://purl.obolibrary.org/obo/hp.json')\n",
    "metadata = MetaData(created_by=\"ORCID:0000-0002-0736-9199\")\n",
    "metadata.default_versions_with_hpo(version=o.version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7faffa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Loading neonatal data [{0}].'.format(\"/Users/gargam/Develop/neonatal-packets/examples/pexample.csv\"))\n",
    "df = pd.read_csv(\"/Users/gargam/Develop/neonatal-packets/examples/pexample.csv\", sep=\"\\t\", keep_default_na=False)\n",
    "done()\n",
    "logging.info(\"Identifying hpo columns..\")\n",
    "logging.info(\"Scanning samples that have no phenotypes..\")\n",
    "phenotype_col = \"Anomalies with HPO codes (Screening)\"\n",
    "empty_idx = np.where(df[phenotype_col].eq('') | df[phenotype_col].isna())[0].tolist()\n",
    "empty_samples = [df.iloc[i, 0] for i in empty_idx]\n",
    "logging.info(empty_samples)\n",
    "\n",
    "logging.info(\"Dropping empties..\")\n",
    "df.drop(empty_idx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2556e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hpterm(terms, o):\n",
    "    result = []\n",
    "    for term in terms:\n",
    "        term = o.get_term(term.replace(' ', ''))\n",
    "        if term == None:\n",
    "            print(terms)\n",
    "        result.append(HpTerm(term.identifier.value, term.name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc21c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Mapping rows to phenopackets...\")\n",
    "samples = []\n",
    "for index, row in df.iterrows():\n",
    "    terms = to_hpterm(row[2].split(\",\"), o)\n",
    "    samples.append(Individual(row[0], terms, interpretation_list=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265e53f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Individual.output_individuals_as_phenopackets(samples, metadata = metadata.to_ga4gh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2265503b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "updated",
   "language": "python",
   "name": "updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
